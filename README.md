# Daily Learning Repository

Welcome to my daily learning repository! Here, I document new topics and concepts that I learn every day.
## Purpose
The main purpose of this repository is to track my learning progress and create a reference for myself and others interested in the topics I explore.

Feel free to explore and learn along with me!

## Table of Contents
*April 2024*

| S.N | Title | Note | Completion |
| :--: | ---- | :--: | :--: |
| 1 | What is RAG? | [note](./RAG/README.md) | &#x2610; |
| 2 | RAG vs Finetuning - Which is the Best Tool to Boost Your LLM Application? | [note](./RAG-vs-Finetuning/README.md) | &#x2610; |
| 3 | ZeRO & DeepSpeed | [note](DeepSpeed/README.md) | &#x2610; |
| 4 | Graph RAG |  | &#x2610; |
| 5 | Model Merge |  | &#x2610; |
| 6 | HuggingFace's model Memory Calculator |  | &#x2610; |
| 7 | RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback |  | &#x2610; |
| 8 | Switch Transformers | [note](./Switch-Transformers/README.md) | &#x2610; |
| 9 | Retrieval Meets Long Context LLMs | [note](./Retrieval/README.md) | &#x2610; |
| 10 | Training Language Models to Follow Instructions with Human Feedback | [note](./RLHF/README.md) | &#x2610; |
| 11 | Visual intro to transformers |  | &#x2610; |
| 12 | Visualizing Attention, a Transformer's Heart |  |  |
